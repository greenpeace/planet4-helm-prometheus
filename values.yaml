# https://github.com/prometheus-community/helm-charts/blob/main/charts/kube-prometheus-stack/values.yaml
---
prometheus:
  prometheusSpec:
    additionalAlertManagerConfigs:
      - scheme: https
        tls_config:
          ca_file: /certs/cacerts.pem
          cert_file: /certs/tls.crt
          key_file: /certs/tls.key
          server_name: "alertmanager-0.greenpeace.net"
        static_configs:
          - targets:
              - "alertmanager-0.greenpeace.net"
      - scheme: https
        tls_config:
          ca_file: /certs/cacerts.pem
          cert_file: /certs/tls.crt
          key_file: /certs/tls.key
          server_name: "alertmanager-1.greenpeace.net"
        static_configs:
          - targets:
              - "alertmanager-1.greenpeace.net"
      - scheme: https
        tls_config:
          ca_file: /certs/cacerts.pem
          cert_file: /certs/tls.crt
          key_file: /certs/tls.key
          server_name: "alertmanager-2.greenpeace.net"
        static_configs:
          - targets:
              - "alertmanager-2.greenpeace.net"
    storageSpec:
      volumeClaimTemplate:
        spec:
          storageClassName: standard
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 40Gi
    resources:
      requests:
        cpu: 2500m
        memory: 5Gi
      limits:
        cpu: 4000m
    volumes:
      - name: certs
        secret:
          secretName: thanos-tls
    volumeMounts:
      - name: certs
        mountPath: "/certs"
        readOnly: true
    retention: 10d
    thanos:
      version: v0.20.1
      objectStorageConfig:
        existingSecret:
          name: thanos-key
          key: objstore.yml
  thanosService:
    enabled: true
  thanosIngress:
    enabled: true
    ingressClassName: redirects-nginx
    pathType: ImplementationSpecific
    annotations:
      nginx.ingress.kubernetes.io/backend-protocol: GRPC
      nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
      nginx.ingress.kubernetes.io/grpc-backend: "true"
      nginx.ingress.kubernetes.io/protocol: h2c
      nginx.ingress.kubernetes.io/proxy-read-timeout: "160"
      nginx.ingress.kubernetes.io/auth-tls-verify-client: "on"
      nginx.ingress.kubernetes.io/auth-tls-verify-depth: "2"
      nginx.ingress.kubernetes.io/auth-tls-secret: "kube-system/thanos-tls"
prometheusOperator:
  createCustomResource: false
windowsMonitoring:
  enabled: false

grafana:
  enabled: false

kube-state-metrics:
  resources:
    limits:
    requests:
      cpu: 10m
      memory: 32Mi

alertmanager:
  enabled: false

defaultRules:
  create: true
  rules:
    # GKE doesn't deploy a kubeScheduler
    kubeSchedulerAlerting: false
    # GKE Kube Proxy is not referenced properly with this mixin alert
    kubeProxy: false
  disabled:
    # If Prometheus is failing to send alerts to any Alertmanager we will not
    # see this alert. It is therefore redundant. Instead we will be notified
    # via the watchdog alert sent to Healthchecks.io
    PrometheusErrorSendingAlertsToAnyAlertmanager: true
    # Our environment is not mature enough for this alert.
    # Until we have properly defined resource requests,
    # it is only contributing to alert fatigue.
    # Additionally it is missing a runbook:
    # https://runbooks.prometheus-operator.dev/runbooks/node/nodesystemsaturation
    # https://github.com/prometheus-community/helm-charts/issues/3893
    NodeSystemSaturation: true
    # We have specific deployments that need to ignore this alert
    KubeHpaMaxedOut: true
    # This alert flaps often, isn't critical, and isn't prioritised.
    NodeFilesystemFilesFillingUp: true

kubeControllerManager:
  enabled: false

coreDns:
  enabled: false

kubeDns:
  enabled: true
