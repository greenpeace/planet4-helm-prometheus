---
additionalPrometheusRulesMap:
  planet4:
    groups:
      - name: P4Probes
        rules:
          - alert: SlowProbe
            annotations:
              description: |-
                {{$labels.instance}} probe is taking {{$value}}
                seconds to response
              observability_url: >-
                https://grafana.greenpeace.org/d/na0nQDXGk/planet4-end-point-monitoring?orgId=1&var-target={{$labels.instance}}
              runbook_url: >-
                https://docs.google.com/document/d/1YgbkEDgENyxJ67QZ5VeVTh-uZfv8UCKvDGv553CvqBQ/edit#bookmark=id.9as4myvdzik2
              summary: "A P4 probe is responding slowly"
              gitlab_incident_markdown: |
                /label  ~\"Terraform Deployment\"\n Probe slow
            expr: >-
              ((probe_success == 1)
              and
              (avg_over_time(probe_duration_seconds[1m]) > 2.5))
              * probe_duration_seconds
            for: 2m
            labels:
              email_contact: pops@greenpeace.org
              gitlab_project: planet4-documentation-and-issues
              severity: high
              slack_channel: p4-slack-alert
          - alert: ProbeHTTPErrorCode
            annotations:
              description: |-
                {{$labels.instance}} probe returned a {{$value}} error code.
              observability_url: >-
                https://grafana.greenpeace.org/d/na0nQDXGk/planet4-end-point-monitoring?orgId=1&var-target={{$labels.instance}}
              runbook_url: >-
                https://docs.google.com/document/d/1YgbkEDgENyxJ67QZ5VeVTh-uZfv8UCKvDGv553CvqBQ/edit#bookmark=id.xorjr89c765l
              summary: "A P4 instance returned an invalid HTTP status code"
              gitlab_incident_markdown: |-
                /label  ~\"Terraform Deployment\"\n
                HTTP probe returned error {{ $value }}
            expr: |
              probe_http_status_code <= 199 OR probe_http_status_code >= 400
            for: 2m
            labels:
              email_contact: pops@greenpeace.org
              gitlab_project: planet4-documentation-and-issues
              severity: critical
              slack_channel: p4-slack-alert
      - name: P4ElasticSearch
        rules:
          - alert: ElasticSearchClusterRed
            annotations:
              description: >-
                Elastic Search Cluster is Red
              observability_url: >-
                https://grafana.greenpeace.org/goto/mcFYK-ZSR?orgId=1
              runbook_url: >-
                https://www.notion.so/p4infra/ElasticSearch-investigations-07ef977847764bcfbaf8240a7c843da2
              summary: "An Elastic Search Cluster is RED"
              gitlab_incident_markdown: |-
                /label  ~\"Terraform Deployment\"\n
                Elastic Search Cluster is RED
            expr: |-
              elasticsearch_cluster_health_status{color="red"} == 1
            for: 5m
            labels:
              email_contact: pops@greenpeace.org
              gitlab_project: planet4-documentation-and-issues
              severity: high
              slack_channel: p4-slack-alert
          - alert: ElasticSearchClusterYellow
            annotations:
              description: >-
                Elastic Search Cluster is Yellow
              observability_url: >-
                https://grafana.greenpeace.org/goto/mcFYK-ZSR?orgId=1
              runbook_url: >-
                https://www.notion.so/p4infra/ElasticSearch-investigations-07ef977847764bcfbaf8240a7c843da2
              summary: "An Elastic Search Cluster is YELLOW"
              gitlab_incident_markdown: |-
                /label  ~\"Terraform Deployment\"\n
                Elastic Search Cluster is YELLOW
            expr: |-
              elasticsearch_cluster_health_status{color="yellow"} == 1
            for: 5m
            labels:
              gitlab_project: planet4-documentation-and-issues
              severity: medium
              slack_channel: p4-slack-alert
      - name: P4cert-manager
        rules:
          - alert: cert-managerCertExpiring
            annotations:
              description: >-
                "Cert-manager certificate for {{$labels.name}} in {{$labels.cluster}} expires in {{$value}} days"
              observability_url: >-
                https://grafana.greenpeace.org/d/7YTxIodVz/global-certificates-overview?orgId=1
              runbook_url: >-
                https://gitlab.greenpeace.org/gp/git/operations/infrastructure/google-cloud-platform/git-ops-k8s/cert-manager-helm-chart/-/wikis/Runbook
              summary: TLS Certificate is going to expire.
            expr: >-
              floor(0 < ((min(certmanager_certificate_expiration_timestamp_seconds) by (name, cluster, issuer_name) - time()) /60/60/24 ) < 14)
            for: 5m
            labels:
              gitlab_project: planet4-documentation-and-issues
              severity: Warning
              slack_channel: p4-slack-alert
          - alert: cert-managerCertExpired
            annotations:
              description: >-
                Cert-manager certificate for {{$labels.name}} in {{$labels.cluster}} expired {{$value}} days ago
              observability_url: >-
                https://grafana.greenpeace.org/d/7YTxIodVz/global-certificates-overview?orgId=1
              runbook_url: >-
                https://gitlab.greenpeace.org/gp/git/operations/infrastructure/google-cloud-platform/git-ops-k8s/cert-manager-helm-chart/-/wikis/Runbook
              summary: TLS Certificate is going to expire.
            expr: >-
              floor(abs(((min(certmanager_certificate_expiration_timestamp_seconds) by (name, cluster, issuer_name) - time()) /60/60/24 ) < 0))
            for: 5m
            labels:
              gitlab_project: planet4-documentation-and-issues
              severity: Warning
              slack_channel: p4-slack-alert
      - name: P4ThanosSidecar
        rules:
          - alert: ThanosSidecarNotRunning
            annotations:
              description: >-
                thanos-sidecar container is not running in {{$labels.cluster}}.
                Metrics will not be uploaded to long-term storage,
                and will be lost if not resolved before Prometheus' retention
                period.
              observability_url: >-
                https://grafana.greenpeace.org/goto/rkFAK-ZSg?orgId=1
              summary: >-
                Thanos sidecar container is not running in {{$labels.cluster}}.
              gitlab_incident_markdown: ""
            expr: >-
              kube_pod_container_status_running{container="thanos-sidecar"} == 0
            for: 5m
            labels:
              email_contact: pops@greenpeace.org
              gitlab_project: planet4-documentation-and-issues
              severity: critical
              slack_channel: p4-slack-alert
      - name: P4KubernetesRules
        rules:
          - alert: KubernetesNodeNotReady
            annotations:
              description: >-
                Kubernetes node not ready
                (instance {{ $labels.instance }})
              summary: "Kubernetes node not ready"
              gitlab_incident_markdown: |
                /label  ~\"Terraform Deployment\"\n node not ready
            expr: >-
              kube_node_status_condition{
               condition="Ready",
               status="true"
               } == 0
            for: 5m
            labels:
              email_contact: pops@greenpeace.org
              gitlab_project: planet4-documentation-and-issues
              severity: high
              slack_channel: p4-slack-alert
          - alert: KubernetesPodCrashLooping
            annotations:
              description: >-
                Pod is crashlooping
                VALUE = {{ $value }}
                LABELS = {{ $labels }}
              summary: "Kubernetes pod crash looping"
              gitlab_incident_markdown: |
                /label  ~\"Terraform Deployment\"\n pod crashlooping
            expr: >-
              increase(
               kube_pod_container_status_restarts_total[10m]
               ) > 3
            for: 2m
            labels:
              email_contact: pops@greenpeace.org
              gitlab_project: planet4-documentation-and-issues
              severity: Critical
              slack_channel: p4-slack-alert
          - alert: KubernetesApiServerErrors
            annotations:
              description: >-
                Kubernetes API server is
                experiencing high error rate
              summary: "Kubernetes API server errors"
              gitlab_incident_markdown: |
                /label  ~\"Terraform Deployment\"\n APIServer Error
            expr: >-
              sum(rate(apiserver_request_total{
               job="apiserver",
               code=~"^(?:5..)$"
               }[1m])) by (instance)/ sum(rate(apiserver_request_total{
                 job="apiserver"
                 }[1m])) by (instance) * 100 > 3
            for: 2m
            labels:
              email_contact: pops@greenpeace.org
              gitlab_project: planet4-documentation-and-issues
              severity: Critical
              slack_channel: p4-slack-alert
